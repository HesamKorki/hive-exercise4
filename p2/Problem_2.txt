(a)

The commands I ran through the beeline client is available in the file 
`P2_a.q`. First, I created two external tables for the tsv files then two 
clustered tables. Lastly, we loaded data from the external table to the clustered 
tables which took some time since the buckets are sorted by nconst.

This is the result of the describe on the names_clustered table:
+-----------------------------+----------------------------------------------------+----------+
|          col_name           |                     data_type                      | comment  |
+-----------------------------+----------------------------------------------------+----------+
| nconst                      | string                                             |          |
| primaryname                 | string                                             |          |
| birthyear                   | int                                                |          |
| deathyear                   | int                                                |          |
| primaryprofession           | string                                             |          |
| knownfortitles              | string                                             |          |
|                             | NULL                                               | NULL     |
| Detailed Table Information  | Table(tableName:name_basics_clustered, dbName:default, owner:dataflair, createTime:1704026636, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:nconst, type:string, comment:null), FieldSchema(name:primaryname, type:string, comment:null), FieldSchema(name:birthyear, type:int, comment:null), FieldSchema(name:deathyear, type:int, comment:null), FieldSchema(name:primaryprofession, type:string, comment:null), FieldSchema(name:knownfortitles, type:string, comment:null)], location:file:/mnt/irisgpfs/users/hkorki/hive_tables/names_clustered, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:8, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[nconst], sortCols:[Order(col:nconst, order:1)], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=791858005, numRows=13023618, rawDataSize=778834387, COLUMN_STATS_ACCURATE={\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"birthyear\":\"true\",\"deathyear\":\"true\",\"knownfortitles\":\"true\",\"nconst\":\"true\",\"primaryname\":\"true\",\"primaryprofession\":\"true\"}}, numFiles=8, transient_lastDdlTime=1704026855, bucketing_version=2, SORTBUCKETCOLSPREFIX=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false, catName:hive, ownerType:USER) |          |
+-----------------------------+----------------------------------------------------+----------+
8 rows selected (0.219 seconds)

This is the describe of principals clustered table:
+-----------------------------+----------------------------------------------------+----------+
|          col_name           |                     data_type                      | comment  |
+-----------------------------+----------------------------------------------------+----------+
| tconst                      | string                                             |          |
| ordering                    | int                                                |          |
| nconst                      | string                                             |          |
| category                    | string                                             |          |
| job                         | string                                             |          |
| characters                  | string                                             |          |
|                             | NULL                                               | NULL     |
| Detailed Table Information  | Table(tableName:title_principals_clustered, dbName:default, owner:dataflair, createTime:1704026712, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:tconst, type:string, comment:null), FieldSchema(name:ordering, type:int, comment:null), FieldSchema(name:nconst, type:string, comment:null), FieldSchema(name:category, type:string, comment:null), FieldSchema(name:job, type:string, comment:null), FieldSchema(name:characters, type:string, comment:null)], location:file:/mnt/irisgpfs/users/hkorki/hive_tables/principals_clustered, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:8, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[nconst], sortCols:[Order(col:nconst, order:1)], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{totalSize=2605646894, numRows=59150423, rawDataSize=2546496471, COLUMN_STATS_ACCURATE={\"BASIC_STATS\":\"true\",\"COLUMN_STATS\":{\"category\":\"true\",\"characters\":\"true\",\"job\":\"true\",\"nconst\":\"true\",\"ordering\":\"true\",\"tconst\":\"true\"}}, numFiles=8, transient_lastDdlTime=1704027269, bucketing_version=2, SORTBUCKETCOLSPREFIX=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false, catName:hive, ownerType:USER) |          |
+-----------------------------+----------------------------------------------------+----------+
8 rows selected (0.12 seconds)

Listing the files of the warehouse directory, for the external files we just see 
the tsv file and a hidden file '.file_name.tsv.crc`. However, the clustered tables 
directory have 8 files (as much as the buckets):
000000_0  000002_0  000004_0  000006_0
000001_0  000003_0  000005_0  000007_0


(b)

Firstly, I tried doing the Mapside join on the external tables that are not bucketized 
to be able to compare. I ran the following command:

time beeline -n dataflair -u jdbc:hive2://localhost:10000 --silent=true -f ./2b.q > 2b.txt

which took 12:48 minutes

2b.q just contains the the first 3 lines of `P2_b.q` file.

Then, as instructed, I activated the bucketmapjoin:

set hive.auto.convert.sortmerge.join=true;
set hive.optimize.bucketmapjoin=true;
set hive.optimize.bucketmapjoin.sortedmerge=true;

I first tried to get an EXPLAIN of the query that I wanted to run 
to see if it would indeed used bucket mapjoin, this was the output:
+----------------------------------------------------+
|                      Explain                       |
+----------------------------------------------------+
| STAGE DEPENDENCIES:                                |
|   Stage-1 is a root stage                          |
|   Stage-0 depends on stages: Stage-1               |
|                                                    |
| STAGE PLANS:                                       |
|   Stage: Stage-1                                   |
|     Map Reduce                                     |
|       Map Operator Tree:                           |
|           TableScan                                |
|             alias: title_principals_clustered      |
|             Statistics: Num rows: 59150423 Data size: 2546496471 Basic stats: COMPLETE Column stats: NONE |
|             Filter Operator                        |
|               predicate: nconst is not null (type: boolean) |
|               Statistics: Num rows: 59150423 Data size: 2546496471 Basic stats: COMPLETE Column stats: NONE |
|               Select Operator                      |
|                 expressions: tconst (type: string), ordering (type: int), nconst (type: string), category (type: string), job (type: string), characters (type: string) |
|                 outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 |
|                 Statistics: Num rows: 59150423 Data size: 2546496471 Basic stats: COMPLETE Column stats: NONE |
|                 Sorted Merge Bucket Map Join Operator |
|                   condition map:                   |
|                        Inner Join 0 to 1           |
|                   keys:                            |
|                     0 _col0 (type: string)         |
|                     1 _col2 (type: string)         |
|                   outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11 |
|                   File Output Operator             |
|                     compressed: false              |
|                     table:                         |
|                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat |
|                         output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat |
|                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe |
|                                                    |
|   Stage: Stage-0                                   |
|     Fetch Operator                                 |
|       limit: -1                                    |
|       Processor Tree:                              |
|         ListSink                                   |
|                                                    |
+----------------------------------------------------+
In which I could clearly see Sorted Merge Bucket Map Join Operator that verified 
that everything is ready.

Then I ran the following:

time beeline -n dataflair -u jdbc:hive2://localhost:10000 --silent=true -f ./2b_cluster.q > 2b_c.txt

which took 08:23 minutes.

(c)

using the same commands on queries from the first question:

time beeline -n dataflair -u jdbc:hive2://localhost:10000 --silent=true -f ./1a_cluster.q > 1a_c.txt

I watched a noticable performance gain when using the clustered tables:
(times are reported in minutes)

    Query          time         clustered_time
     (a)           8:11             6:49
     (b)           13:54            10:32
     (c)           13:44            10:11